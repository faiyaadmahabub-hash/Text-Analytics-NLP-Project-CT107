{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e352f6a3",
   "metadata": {},
   "source": [
    "Q3 \n",
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e391e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q3 we're using data_2 \n",
    "with open(\"../Data/Data_2.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    inputData = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e11da6",
   "metadata": {},
   "source": [
    "Testing if it was opened properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "befb3925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The big black dog barked at the white cat and chased away.\n"
     ]
    }
   ],
   "source": [
    "print(inputData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb47ee2",
   "metadata": {},
   "source": [
    "1) 3 pos tagging methods demonstration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27bbf639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/afanasevartur/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/afanasevartur/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports \n",
    "import nltk \n",
    "from textblob import TextBlob\n",
    "from nltk import pos_tag, word_tokenize, RegexpTagger\n",
    "\n",
    "#launch\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d45c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'big', 'black', 'dog', 'barked', 'at', 'the', 'white', 'cat', 'and', 'chased', 'away', '.']\n"
     ]
    }
   ],
   "source": [
    "#tokenization\n",
    "\n",
    "inputData_tokenized = word_tokenize(inputData)\n",
    "print(inputData_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2622d775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. NLTK POS Tagger Output:\n",
      "[('The', 'DT'), ('big', 'JJ'), ('black', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('white', 'JJ'), ('cat', 'NN'), ('and', 'CC'), ('chased', 'VBD'), ('away', 'RB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# 1. NLTK POS Tagger\n",
    "print(\"1. NLTK POS Tagger Output:\")\n",
    "nltk_tags = pos_tag(inputData_tokenized)\n",
    "print(nltk_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e583fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. TextBlob POS Tagger Output:\n",
      "[('The', 'DT'), ('big', 'JJ'), ('black', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('white', 'JJ'), ('cat', 'NN'), ('and', 'CC'), ('chased', 'VBD'), ('away', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "# 2. TextBlob POS Tagger\n",
    "print(\"2. TextBlob POS Tagger Output:\")\n",
    "blob = TextBlob(inputData)\n",
    "textblob_tags = blob.tags\n",
    "print(textblob_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbc9afba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Regular Expression Tagger Output:\n",
      "[('The', 'DT'), ('big', 'JJ'), ('black', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('white', 'JJ'), ('cat', 'NN'), ('and', 'CC'), ('chased', 'VBD'), ('away', 'RB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    " # 3. Regular Expression Tagger\n",
    "patterns = [\n",
    "    (r'(?i)^(the|a|an)$', 'DT'), # Determiners/articles (The, the)\n",
    "    (r'.*ed$', 'VBD'), # Past tense verbs (barked, chased)\n",
    "    (r'^(at|in|on|by)$', 'IN'), # Prepositions (at)\n",
    "    (r'^(and|but|or)$', 'CC'), # Conjunctions (and)\n",
    "    (r'^(away|here|there)$', 'RB'), # Adverbs (away)\n",
    "    (r'^(big|black|white)$', 'JJ'), # Adjectives (big, black, white)\n",
    "    (r'^\\.$', '.'), # Period at the end of a sentence\n",
    "    (r'.*', 'NN') # By default, everything else is considered a noun (dog, cat)\n",
    "    ]\n",
    "print(\"3. Regular Expression Tagger Output:\")\n",
    "regexp_tagger = RegexpTagger(patterns)\n",
    "regexp_tags = regexp_tagger.tag(inputData_tokenized)\n",
    "print(regexp_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78354041",
   "metadata": {},
   "source": [
    "2) Differences Explanation\n",
    "\n",
    "The most important obvious difference between these 3 methods is that NLTK and TextBlob rely on statistical machine learning models trained on huge corpora of text, while Regular Expression (Regex) Tagger is a strictly deterministic algorithm based on human-written rules.\n",
    "\n",
    "breakdown by criterias:\n",
    "\n",
    "Accuracy - \n",
    "NLTK and TextBlob: Highly accurate. They analyze the context of a sentence. For the phrase \"The big black dog barked...,\" they will accurately identify \"barked\" as a past tense verb (VBD) and \"dog\" as a noun (NN), based on the probability distribution of words around them.\n",
    "Regex Tagger: Has extremely low accuracy on general text. Its accuracy is 100% only for words that strictly match the specified regular expressions, and 0% for all others. It doesn't understand context (for example, it won't distinguish the word \"book\" as a book from \"book\" as a reservation, unless a strict rule is specified).\n",
    "\n",
    "Tag Sets - \n",
    "NLTK and TextBlob: Out of the box, they use the standardized Penn Treebank tag set (e.g., NN for nouns, JJ for adjectives, VBD for past tense verbs). They understand and apply dozens of different tags for fine-grained classification.\n",
    "Regex Tagger: The tag set is entirely up to the programmer. The developer must manually specify the pattern conformance to the Penn Treebank standard (as we did in the code: .*ed$ -> VBD). Any omission will result in incorrect tagging (for example, irregular verbs like \"slept\" will not match the .*ed$ rule).\n",
    "\n",
    "Performance - \n",
    "Regex Tagger: Wins in pure computation speed at the micro-level. String matching using regular expressions is lightning fast and doesn't require loading heavy models into RAM. However, creating a complex system of rules for the entire English language would take years of manual effort.\n",
    "NLTK and TextBlob: They require time for initialization (loading pre-trained models, such as averaged_perceptron_tagger ) and consume more RAM. However, on the scale of real-world problems, their efficiency is incomparably higher, as they process any text without the need to write new rules.\n",
    "\n",
    "Use Cases - \n",
    "NLTK: The industry standard for academic and complex NLP tasks. Used when full control over the natural language processing pipeline and high accuracy are required.\n",
    "TextBlob: Ideal for rapid prototyping. It's a wrapper around NLTK, providing a simpler and more intuitive API. Suitable for basic analytics tasks where you need to write code quickly and without unnecessary configuration.\n",
    "Regex Tagger: Absolutely unsuitable as a standalone tagger for general-purpose text. However, it is indispensable in two cases:\n",
    "As a backoff tagger when the statistical model fails to handle an unknown word.\n",
    "For highly specialized subject areas (e.g., extracting and tagging specific part numbers, phone numbers, or currency codes with a rigid structure)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4fa553",
   "metadata": {},
   "source": [
    "3) Parse Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c43c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
